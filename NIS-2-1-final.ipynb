{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1 из части II\n",
    "**Выполнила Гайдук Юлия, МЖД172**\n",
    "\n",
    "Выполнить лемматизацию выбранных 1-2 текстов на русском языке, разных жанров и среднего размера (3-7 страниц) с помощью морфологического модуля.  \n",
    "\n",
    "Для каждого текста упорядочить леммы по их частоте, вывести первые 25 частотных и 25 наименее частотных лемм.\n",
    "\n",
    "Лемматизация будет выполняться с помощью морфологического модуля pymorphy2.\n",
    "\n",
    "Для примера взяты \"Слово о полку Игореве\" (поэма) и \"Вьюга\" М. А. Булгакова (рассказ)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r'C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python36-32\\Lib\\site-packages')\n",
    "import pymorphy2\n",
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала создадим необходимые функции для удаления пунктуации, разбивки на слова, лемматизации и подсчёта частот. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_text(text):\n",
    "    # Убирает знаки препинания, разделяет текст на слова\n",
    "    import re\n",
    "    no_punct = re.sub(r'[^\\w\\s]','', text)\n",
    "    txt = no_punct.split()\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_text(text):\n",
    "    # На вход подаётся список. Каждое слово из списка приводится в начальную форму.\n",
    "    # Возвращает список лемм.\n",
    "    normed_text = []\n",
    "    for word in text:\n",
    "        normed_word = morph.parse(word)[0].normal_form\n",
    "        normed_text.append(normed_word)\n",
    "    return normed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_forms(text):\n",
    "    # На вход подаётся список лемм.\n",
    "    # Возвращает словарь, где ключами являются леммы, \n",
    "    # а значениями — количество появлений леммы в тексте.\n",
    "    from collections import Counter\n",
    "    c = Counter()\n",
    "    for word in text:\n",
    "        c.update({word:1})\n",
    "    return dict(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполним лемматизацию и подсчёт на примере \"Слова о полку Игореве\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 самых частотных лемм в 'Слове о полку Игореве':\n",
      "('и', 105)\n",
      "('на', 73)\n",
      "('в', 58)\n",
      "('а', 44)\n",
      "('земля', 41)\n",
      "('с', 34)\n",
      "('не', 33)\n",
      "('по', 31)\n",
      "('свой', 31)\n",
      "('он', 30)\n",
      "('князь', 30)\n",
      "('ты', 28)\n",
      "('к', 28)\n",
      "('русский', 27)\n",
      "('игорь', 26)\n",
      "('быть', 20)\n",
      "('уже', 19)\n",
      "('за', 19)\n",
      "('брат', 18)\n",
      "('храбрый', 18)\n",
      "('половецкий', 18)\n",
      "('слава', 16)\n",
      "('о', 15)\n",
      "('дон', 15)\n",
      "('под', 14)\n"
     ]
    }
   ],
   "source": [
    "with open('slovo.txt') as f:\n",
    "    from operator import itemgetter\n",
    "    text = f.read()\n",
    "    prep_txt = prepare_text(text)\n",
    "    norm_txt = normalize_text(prep_txt)\n",
    "    counted = list(sorted(count_forms(norm_txt).items(), key=itemgetter(1), reverse=True))\n",
    "    print(\"25 самых частотных лемм в 'Слове о полку Игореве':\")\n",
    "    for pair in counted[:25]:\n",
    "        print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 наименее частотных лемм в 'Слове о полку Игореве':\n",
      "('печальный', 1)\n",
      "('игорёв', 1)\n",
      "('нет', 1)\n",
      "('пусть', 1)\n",
      "('начаться', 1)\n",
      "('быль', 1)\n",
      "('наш', 1)\n",
      "('замышление', 1)\n",
      "('кома', 1)\n",
      "('растекаться', 1)\n",
      "('сизый', 1)\n",
      "('помнить', 1)\n",
      "('прежний', 1)\n",
      "('какой', 1)\n",
      "('настигать', 1)\n",
      "('зарезать', 1)\n",
      "('редедь', 1)\n",
      "('касожский', 1)\n",
      "('перст', 1)\n",
      "('струна', 1)\n",
      "('возлагать', 1)\n",
      "('рокотать', 1)\n",
      "('укрепить', 1)\n",
      "('поострить', 1)\n",
      "('мужество', 1)\n"
     ]
    }
   ],
   "source": [
    "with open('slovo.txt') as f:\n",
    "    from operator import itemgetter\n",
    "    text = f.read()\n",
    "    prep_txt = prepare_text(text)\n",
    "    norm_txt = normalize_text(prep_txt)\n",
    "    counted = list(sorted(count_forms(norm_txt).items(), key=itemgetter(1), reverse=False))\n",
    "    print(\"25 наименее частотных лемм в 'Слове о полку Игореве':\")\n",
    "    for pair in counted[:25]:\n",
    "        print(pair)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь возьмём для анализа рассказ \"Вьюга\" М. А. Булгакова."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 самых частотных лемм в рассказе 'Вьюга':\n",
      "('я', 189)\n",
      "('и', 135)\n",
      "('в', 120)\n",
      "('не', 60)\n",
      "('что', 55)\n",
      "('на', 52)\n",
      "('он', 47)\n",
      "('быть', 37)\n",
      "('а', 35)\n",
      "('как', 30)\n",
      "('с', 29)\n",
      "('у', 27)\n",
      "('по', 20)\n",
      "('она', 19)\n",
      "('из', 19)\n",
      "('потом', 19)\n",
      "('мы', 19)\n",
      "('лошадь', 19)\n",
      "('стать', 18)\n",
      "('к', 18)\n",
      "('за', 18)\n",
      "('но', 17)\n",
      "('возница', 17)\n",
      "('это', 16)\n",
      "('аксинья', 15)\n"
     ]
    }
   ],
   "source": [
    "with open('bulgakov.txt') as f:\n",
    "    from operator import itemgetter\n",
    "    text = f.read()\n",
    "    prep_txt = prepare_text(text)\n",
    "    norm_txt = normalize_text(prep_txt)\n",
    "    counted = list(sorted(count_forms(norm_txt).items(), key=itemgetter(1), reverse=True))\n",
    "    print(\"25 самых частотных лемм в рассказе 'Вьюга':\")\n",
    "    for pair in counted[:25]:\n",
    "        print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 наименее частотных лемм в рассказе 'Вьюга':\n",
      "('зверь', 1)\n",
      "('заплакать', 1)\n",
      "('дитя', 1)\n",
      "('история', 1)\n",
      "('начаться', 1)\n",
      "('всезнающий', 1)\n",
      "('пальчик', 1)\n",
      "('проживать', 1)\n",
      "('влюбиться', 1)\n",
      "('дочь', 1)\n",
      "('любовь', 1)\n",
      "('пламенный', 1)\n",
      "('иссушать', 1)\n",
      "('беднягино', 1)\n",
      "('съездить', 1)\n",
      "('уездный', 1)\n",
      "('город', 1)\n",
      "('заказать', 1)\n",
      "('выйти', 1)\n",
      "('ослепительный', 1)\n",
      "('возможно', 1)\n",
      "('серый', 1)\n",
      "('полоска', 1)\n",
      "('конторский', 1)\n",
      "('штаны', 1)\n"
     ]
    }
   ],
   "source": [
    "with open('bulgakov.txt') as f:\n",
    "    from operator import itemgetter\n",
    "    text = f.read()\n",
    "    prep_txt = prepare_text(text)\n",
    "    norm_txt = normalize_text(prep_txt)\n",
    "    counted = list(sorted(count_forms(norm_txt).items(), key=itemgetter(1), reverse=False))\n",
    "    print(\"25 наименее частотных лемм в рассказе 'Вьюга':\")\n",
    "    for pair in counted[:25]:\n",
    "        print(pair)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Выводы**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* В списках частотности лемм в обоих произведениях топ занимают в основном служебные слова.\n",
    "* В зависимости от жанра, времени написания и других характеристик в топе частотности также будут встречаться характерные слова. Так, в \"Слове о полку Игореве\" в топе частотности мы видим такие слова как *земля*, *князь* и *русский*, а у Булгакова — *лошадь* и *возница*. Такие находки в топах частотности позволяют делать предположения и догадки о содержании текста."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
